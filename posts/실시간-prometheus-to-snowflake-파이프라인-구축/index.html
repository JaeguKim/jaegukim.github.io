<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="실시간 Prometheus To Snowflake 파이프라인 구축" /><meta name="author" content="Jaegoo Kim" /><meta property="og:locale" content="en" /><meta name="description" content="프로젝트 배경" /><meta property="og:description" content="프로젝트 배경" /><link rel="canonical" href="https://jaegukim.github.io/posts/%EC%8B%A4%EC%8B%9C%EA%B0%84-prometheus-to-snowflake-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8-%EA%B5%AC%EC%B6%95/" /><meta property="og:url" content="https://jaegukim.github.io/posts/%EC%8B%A4%EC%8B%9C%EA%B0%84-prometheus-to-snowflake-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8-%EA%B5%AC%EC%B6%95/" /><meta property="og:site_name" content="Study Log" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-01-16T11:58:00+08:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="실시간 Prometheus To Snowflake 파이프라인 구축" /><meta name="twitter:site" content="@JaeguKim" /><meta name="twitter:creator" content="@Jaegoo Kim" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Jaegoo Kim"},"dateModified":"2022-03-26T17:31:57+08:00","datePublished":"2022-01-16T11:58:00+08:00","description":"프로젝트 배경","headline":"실시간 Prometheus To Snowflake 파이프라인 구축","mainEntityOfPage":{"@type":"WebPage","@id":"https://jaegukim.github.io/posts/%EC%8B%A4%EC%8B%9C%EA%B0%84-prometheus-to-snowflake-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8-%EA%B5%AC%EC%B6%95/"},"url":"https://jaegukim.github.io/posts/%EC%8B%A4%EC%8B%9C%EA%B0%84-prometheus-to-snowflake-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8-%EA%B5%AC%EC%B6%95/"}</script><title>실시간 Prometheus To Snowflake 파이프라인 구축 | Study Log</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Study Log"><meta name="application-name" content="Study Log"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="https://avatars.githubusercontent.com/u/22807942?s=460&u=cc1d822a8be2c87ac3aa4917adaadeca5487c515&v=4" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Study Log</a></div><div class="site-subtitle font-italic">“ In order to be irreplaceable, one must always be different” – Coco Chanel</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/JaeguKim" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/JaeguKim" aria-label="twitter" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['kimwithglasses','kakao.com'].join('@')" aria-label="email" class="order-5" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" class="order-6" > <i class="fas fa-rss"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>실시간 Prometheus To Snowflake 파이프라인 구축</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>실시간 Prometheus To Snowflake 파이프라인 구축</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> Jaegoo.Kim </span> on <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Sun, Jan 16, 2022, 11:58 AM +0800" >Jan 16, 2022<i class="unloaded">2022-01-16T11:58:00+08:00</i> </span></div><div> <span> Updated <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Sat, Mar 26, 2022, 6:31 PM +0900" >Mar 26, 2022<i class="unloaded">2022-03-26T17:31:57+08:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="3567 words">19 min read</span></div></div><div class="post-content"><h2 id="프로젝트-배경">프로젝트 배경</h2><p>기존에 동작하던 앱에서는 1분에 한번씩 Prometheus에 실시간으로 수집되고 있는 메트릭을 쿼리하고 S3에 업로드후 Snowflake 데이터 웨어하우스에 적재를 하는 방식으로 동작하였다.</p><h3 id="기존-아키텍처">기존 아키텍처</h3><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/22807942/150488172-ad11cc31-2d3d-45d6-8b5a-bcba34fd78c2.png" alt="image" /></p><h3 id="기존-백필-아키텍처">기존 백필 아키텍처</h3><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/22807942/150488344-694a9728-053d-4f9e-9262-a1d9531b37c3.png" alt="image" /></p><p>이 방식은 다음과 같은 문제점이 있었다.</p><ul><li>데이터 backfill의 어려움 : 프로메테우스의 retention은 6시간으로 설정되어있고, retention이 지나면 프로메테우스로부터 데이터를 받아올 수 없다. retention이 지난경우 백필을 원하면 DevOps팀에게 별도의 Prometheus의 cold storage인 Thanos를 요청해야 했다. Prod환경에서 사용중이던 Thanos는 이미 부하가 많이 걸려있는 상황이기 때문에 사용할 수 없다.<li>backfill Thanos 부하증가 : 몇가지 메트릭의 경우 Thanos에서 대량의 데이터를 로드하여 메모리에 불러오다보니, 자주 장애가 나는 현상이 있었다. Thanos는 리소스를 많이 필요하므로, DevOps팀에서 backfill Thanos 배포를 달가워하지는 않았다.<li>backfill의 불편함 : 언제부터 백필해야 되는지 사람이 수동으로 판단해야 하며, 수동으로 백필 애플리케이션을 재 배포해야 한다. 예를들어, 특정 틱에 쿼리는 성공적으로 수행되었지만 S3에 적재가 안되었거나 Snowflake에 적재가 안된경우 backfill 애플리케이션을 수동으로 배포해주어야한다.<li>데이터 유실이 발생하기 쉬운 구조 : query,S3 upload, snowflake 적재과정에서 어느 한 step에서 잘못되면 데이터가 유실된다.</ul><p>위 문제를 해결하기 위해 이 프로젝트를 수행하게 되었다.</p><h2 id="data-pipeline의-요구사항">Data pipeline의 요구사항</h2><p>해당 데이터 파이프라인은 다음과 같은 요구사항이 있다.</p><ul><li>실시간으로 데이터가 적재될것<li>데이터 유실이 없을것</ul><h2 id="구조-개편과정">구조 개편과정</h2><h3 id="1-데이터-유실방지-방법에-대한-고민">1. 데이터 유실방지 방법에 대한 고민</h3><p>S3 적재, Snowflake 적재 도중 데이터 유실을 방지 하기위해서 Kafka consumer의 offset commit 기능을 떠올렸다. Kafka를 사용하게 되면서 중복로그가 쌓일수 있기 때문에 중복을 어떻게 제거할까도 고민했다. Snowflake는 Unique 키를 지원하지 않기 때문에, 중복 row가 생길수 있었고 이를 위해서 data를 적재하기 전에 해당 row를 delete후 insert하는 방식을 선택했다(merge into 쿼리를 사용하는것도 고려했지만 테이블 풀 스캔이 발생할것 같아서 효율적이지 않을것이라 생각했다). 그래서 나온것이 V1 아키텍쳐이다.</p><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/22807942/150488503-f95198d1-aaf9-474c-9aba-b31b97596573.png" alt="image" /></p><p>Kafka consumer app에서 snowflake에 delete,insert 쿼리를 하나의 트랜잭션으로 처리하기 위해서 다음 처럼 구현했다.</p><div lang="python" class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
</pre><td class="rouge-code"><pre><span class="c1">## Kafka-python
</span>
<span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
    <span class="n">self</span><span class="p">.</span><span class="n">logger</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span><span class="sh">"</span><span class="s">Started running</span><span class="sh">"</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">while</span> <span class="ow">not</span> <span class="n">self</span><span class="p">.</span><span class="n">stop_event</span><span class="p">.</span><span class="nf">is_set</span><span class="p">():</span>
            <span class="n">msg_pack</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">consumer</span><span class="p">.</span><span class="nf">poll</span><span class="p">(</span><span class="n">timeout_ms</span><span class="o">=</span><span class="n">settings</span><span class="p">.</span><span class="n">POLL_SECONDS</span><span class="p">)</span>
            <span class="n">self</span><span class="p">.</span><span class="n">logger</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">number_of_message : </span><span class="si">{</span><span class="nf">len</span><span class="p">(</span><span class="n">msg_pack</span><span class="p">)</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">tp</span><span class="p">,</span> <span class="n">msgs</span> <span class="ow">in</span> <span class="n">msg_pack</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
                <span class="k">for</span> <span class="n">msg</span> <span class="ow">in</span> <span class="n">msgs</span><span class="p">:</span>
                    <span class="n">decoded_key</span> <span class="o">=</span> <span class="n">msg</span><span class="p">.</span><span class="n">key</span><span class="p">.</span><span class="nf">decode</span><span class="p">(</span><span class="sh">'</span><span class="s">utf-8</span><span class="sh">'</span><span class="p">)</span>
                    <span class="n">decoded_value</span> <span class="o">=</span> <span class="n">msg</span><span class="p">.</span><span class="n">value</span><span class="p">.</span><span class="nf">decode</span><span class="p">(</span><span class="sh">'</span><span class="s">utf-8</span><span class="sh">'</span><span class="p">)</span>
                    <span class="n">self</span><span class="p">.</span><span class="n">logger</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span>
                        <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">tp</span><span class="p">.</span><span class="n">topic</span><span class="si">}</span><span class="s">:</span><span class="si">{</span><span class="n">tp</span><span class="p">.</span><span class="n">partition</span><span class="si">}</span><span class="s">:</span><span class="si">{</span><span class="n">msg</span><span class="p">.</span><span class="n">offset</span><span class="si">}</span><span class="s">: key=</span><span class="si">{</span><span class="n">decoded_key</span><span class="si">}</span><span class="s"> value=</span><span class="si">{</span><span class="n">decoded_value</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
                    <span class="n">self</span><span class="p">.</span><span class="nf">delete_and_insert_row</span><span class="p">(</span><span class="n">decoded_value</span><span class="p">)</span>
    <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">self</span><span class="p">.</span><span class="n">logger</span><span class="p">.</span><span class="nf">error</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
        <span class="n">slackManager</span><span class="p">.</span><span class="nf">send_slack_message</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="n">self</span><span class="p">.</span><span class="n">consumer</span><span class="p">.</span><span class="nf">close</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">logger</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span><span class="sh">'</span><span class="s">Consumer closed</span><span class="sh">'</span><span class="p">)</span>
        

<span class="k">def</span> <span class="nf">delete_and_insert_row</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">msg</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="n">msg_dict</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="nf">loads</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
    <span class="n">values_str</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">convert_to_value_str</span><span class="p">(</span><span class="n">msg_dict</span><span class="p">)</span>
    <span class="n">delete_query</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">DELETE FROM </span><span class="si">{</span><span class="n">self</span><span class="p">.</span><span class="n">table_name</span><span class="si">}</span><span class="s"> WHERE TIMESTAMP=</span><span class="sh">'</span><span class="si">{</span><span class="n">msg_dict</span><span class="p">[</span><span class="sh">'</span><span class="s">timestamp</span><span class="sh">'</span><span class="p">]</span><span class="si">}</span><span class="sh">'</span><span class="s"> AND CLUSTER=</span><span class="sh">'</span><span class="si">{</span><span class="n">msg_dict</span><span class="p">[</span><span class="sh">'</span><span class="s">cluster</span><span class="sh">'</span><span class="p">]</span><span class="si">}</span><span class="sh">'</span><span class="s">;</span><span class="sh">"</span>
    <span class="c1"># print(delete_query)
</span>    <span class="n">insert_query</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">INSERT INTO </span><span class="si">{</span><span class="n">self</span><span class="p">.</span><span class="n">table_name</span><span class="si">}</span><span class="s"> VALUES </span><span class="si">{</span><span class="n">values_str</span><span class="si">}</span><span class="s">;</span><span class="sh">"</span>
    <span class="c1"># print(insert_query)
</span>    <span class="n">combined_query</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">delete_query</span><span class="si">}</span><span class="s"> </span><span class="si">{</span><span class="n">insert_query</span><span class="si">}</span><span class="sh">"</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">connector</span><span class="p">.</span><span class="nf">connect</span><span class="p">(</span>
                <span class="n">account</span><span class="o">=</span><span class="n">settings</span><span class="p">.</span><span class="n">SNOWFLAKE_ACCOUNT</span><span class="p">,</span>
                <span class="n">user</span><span class="o">=</span><span class="n">settings</span><span class="p">.</span><span class="n">SNOWFLAKE_USER</span><span class="p">,</span>
                <span class="n">password</span><span class="o">=</span><span class="n">settings</span><span class="p">.</span><span class="n">SNOWFLAKE_PASSWORD</span><span class="p">,</span>
                <span class="n">database</span><span class="o">=</span><span class="n">settings</span><span class="p">.</span><span class="n">DATABASE</span><span class="p">,</span>
                <span class="n">schema</span><span class="o">=</span><span class="n">settings</span><span class="p">.</span><span class="n">SCHEMA</span>
        <span class="p">)</span> <span class="k">as</span> <span class="n">conn</span><span class="p">:</span>
            <span class="n">conn</span><span class="p">.</span><span class="nf">autocommit</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
            <span class="n">cursor_list</span> <span class="o">=</span> <span class="n">conn</span><span class="p">.</span><span class="nf">execute_string</span><span class="p">(</span><span class="n">combined_query</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">cursor</span> <span class="ow">in</span> <span class="n">cursor_list</span><span class="p">:</span>
                <span class="n">query_id</span> <span class="o">=</span> <span class="n">cursor</span><span class="p">.</span><span class="n">sfqid</span>
                <span class="k">while</span> <span class="n">conn</span><span class="p">.</span><span class="nf">is_still_running</span><span class="p">(</span><span class="n">conn</span><span class="p">.</span><span class="nf">get_query_status</span><span class="p">(</span><span class="n">query_id</span><span class="p">)):</span>
                    <span class="n">time</span><span class="p">.</span><span class="nf">sleep</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
            <span class="n">conn</span><span class="p">.</span><span class="nf">commit</span><span class="p">()</span>
            <span class="n">self</span><span class="p">.</span><span class="n">logger</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">DML commited : </span><span class="si">{</span><span class="n">combined_query</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">logger</span><span class="p">.</span><span class="nf">error</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
        <span class="n">slackManager</span><span class="p">.</span><span class="nf">send_slack_message</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">False</span>
    <span class="k">return</span> <span class="bp">True</span>


<span class="k">def</span> <span class="nf">convert_to_value_str</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">msg_dict</span><span class="p">):</span>
    <span class="n">value_list</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="sh">"'</span><span class="si">{</span><span class="nf">str</span><span class="p">(</span><span class="n">val</span><span class="p">)</span><span class="si">}</span><span class="sh">'"</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="nf">list</span><span class="p">(</span><span class="n">msg_dict</span><span class="p">.</span><span class="nf">values</span><span class="p">())]</span>
    <span class="k">return</span> <span class="sa">f</span><span class="sh">'</span><span class="s">(</span><span class="si">{</span><span class="sh">"</span><span class="s">,</span><span class="sh">"</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">value_list</span><span class="p">)</span><span class="si">}</span><span class="s">)</span><span class="sh">'</span>
</pre></table></code></div></div><p>하지만 로그하나당 실행시간이 5초정도 소요되어 실시간으로 테이블을 업데이트할수 없었다.</p><p>Snowflake에서 빠르게 적재하기 위해서 결국 S3 Stage에 적재후 Snowflake에 적재하는 방식으로 돌아가기로 했다. 다만 이 경우에는 중복을 보장할수 없었다. 결국 BI에서 Snowflake에 쿼리시 중복을 제거할수 있도록 해야했고, 원본 테이블에서 DISTINCT 옵션으로 중복을 제거할수 있으리라고 기대했다. 하지만 Prometheus로 부터 받아온 데이터는 다음과 같은 특징이 있었다.</p><ul><li>우리가 쿼리하는 cluster는 여러 shard로 구성되어있고, 각각의 Shard에는 Prometheus가 HA를 위해서 2대로 실행되고 있었다. 이때 각각이 scrape하는 시점이 달라서 같은 시각에 대한 데이터라도 다른 결과가 적재되어 있었다. 즉, 아래와 같이 특정 cluster shard에 쿼리를 했을때 다음과 같이 2개의 값중 랜덤하게 리턴하게 된다.<ul><li>그림</ul></ul><p>그러므로 우리가 중복로그를 필터링 하려면 쿼리에서 value값을 제외한 모든 필드들에 대해서 같은지 확인해야 한다. 그리고 그중에는 timestamp,cluster,shard정보가 항상 존재해야만 어느 cluster shard로 부터 무슨 시간에 대한 데이터인지 구별할 수 있다.</p><p>그래서 해당 필드들을 producer앱에서 메시지를 produce하기전에 추가해주어야 했다.</p><div lang="python" class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>            <span class="c1"># All message should have cluster info to be identified uniquely
</span>            <span class="k">if</span> <span class="sh">'</span><span class="s">cluster</span><span class="sh">'</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">metric_dict</span><span class="p">:</span>
                <span class="n">metric_dict</span><span class="p">[</span><span class="sh">'</span><span class="s">cluster</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="nf">get_cluster_from_url</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
            <span class="k">if</span> <span class="sh">'</span><span class="s">prom_shard</span><span class="sh">'</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">metric_dict</span><span class="p">:</span>
                <span class="n">metric_dict</span><span class="p">[</span><span class="sh">'</span><span class="s">prom_shard</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="nf">get_shard_from_url</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
</pre></table></code></div></div><h3 id="2-consumer-lag에-따라-유동적으로-consumer수-조정하기">2. Consumer lag에 따라 유동적으로 consumer수 조정하기</h3><p>그 다음으로 고려해야 할것은 Consumer의 병렬성이었다. 유저의수가 몰리는 시간대의 경우 메시지의 수가 증가하게 되고, consumer lag에 맞게 consumer의 수를 유기적으로 조정하는것이 필요했다. 그렇게 해서 나온 구조가 v2 아키텍쳐이다.</p><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/22807942/150488602-84a32732-b13c-4aed-a499-2441483aa8f0.png" alt="image" /></p><p>현재 컨슈머앱들은 하나의 Kubernetes Pod로 실행되고 있었고, HPA를 적용하기 위해서 <a href="https://medium.com/@ranrubin/horizontal-pod-autoscaling-hpa-triggered-by-kafka-event-f30fe99f3948">Horizontal Pod Autoscaling (HPA) triggered by Kafka event</a> 글을 참고했다. 이 글이 제시한 방법은 아래와 같이 consumer pod에 kafka exporter를 띄워서 msk broker에 있는 메트릭들을 수집하고 prometheus adapter에서 custom metric api server를 생성하여 HPA에게 kafka consumer lag정보를 제공해주는 방법이다.</p><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/22807942/150488860-7cefaf35-8345-460e-a4c8-a6c81063a673.png" alt="image" /></p><p>위 글이 제시한 방법데로 <code class="language-plaintext highlighter-rouge">Prometheus Adapter</code> Chart의 value를 구성하면 메트릭을 정상적으로 받아오지 못해서, 아래와 같이 values.yaml을 구성했다.</p><div lang="yaml" class="language-yaml highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre><td class="rouge-code"><pre><span class="na">prometheus-adapter</span><span class="pi">:</span>
  <span class="na">prometheus</span><span class="pi">:</span>
    <span class="na">port</span><span class="pi">:</span> <span class="m">9090</span>
    <span class="na">url</span><span class="pi">:</span> <span class="s">http://kube-prometheus-prometheus</span>
  <span class="na">rules</span><span class="pi">:</span>
    <span class="na">custom</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">seriesQuery</span><span class="pi">:</span> <span class="s1">'</span><span class="s">{__name__="kafka_consumergroup_lag",namespace!="",service!="",pod!="",topic!="",consumergroup="MetricConsumerGroup"}'</span>
      <span class="na">resources</span><span class="pi">:</span>
        <span class="na">template</span><span class="pi">:</span> <span class="s">&lt;&lt;.Resource&gt;&gt;</span>
      <span class="na">name</span><span class="pi">:</span>
        <span class="na">matches</span><span class="pi">:</span> <span class="s">^kafka_consumergroup_lag$</span>
        <span class="na">as</span><span class="pi">:</span> <span class="s">kafka_consumergroup_lag</span>
      <span class="na">metricsQuery</span><span class="pi">:</span> <span class="s1">'</span><span class="s">avg_over_time(kafka_consumergroup_lag{&lt;&lt;.LabelMatchers&gt;&gt;}[2m])'</span>
</pre></table></code></div></div><p>위 방법은 pod autoscaling시 kafka exporter 컨테이너 또한 복제가 되므로, 비효율적이다. kafka exporter 컨테이너는 한개이상이 필요없다. Kafka exporter 컨테이너를 consumer pod에서 분리하기 위해서, 외부에 kafka exporter를 단독으로 포함하는 deployment를 생성하고 prometheus adapter에서는 external metric api 서버를 생성하여 해결하려고 했다. 하지만 현재 k8s cluster에는 이미 external metric api server가 존재하였고 추가적으로 생성하는것이 불가능했다. 이미 존재하는 external metric api server은 keda metric adapter에 의해서 생성되고 있었고, 결과적으로 keda를 사용하여 topic별 consumer lag값으로 autoscaling 할수 있었다.</p><h3 id="3-메트릭-프로듀서앱의-장애상황에-대한-대처">3. 메트릭 프로듀서앱의 장애상황에 대한 대처</h3><p>하지만 현재구조에서는 매분마다 데이터 수집로직이 도는데, Producer Pod이 실행도중 종료가 되면, 데이터가 유실이 발생할 수 있다. Producer Pod이 중도에 fail되더라도, Producer가 수행하고 있던 job정보를 저장해둘 독립적인 저장소가 필요했다. 여기서 처음으로 생각했던 해결책은 Producer app에서 1분마다 job을 스케줄링 하기위해서 사용했던 <code class="language-plaintext highlighter-rouge">APScheduler</code> 모듈의 backend를 redis로 사용하여 job정보를 외부 저장소에 저장하는 방법을 생각했다. 하지만 테스트를 다음 처럼 해보니 아주 큰 문제점이 있었다.</p><div lang="python" class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">logging</span>
<span class="kn">import</span> <span class="n">os</span>
<span class="kn">from</span> <span class="n">apscheduler.events</span> <span class="kn">import</span> <span class="n">EVENT_JOB_EXECUTED</span><span class="p">,</span> <span class="n">EVENT_JOB_ERROR</span>
<span class="kn">from</span> <span class="n">apscheduler.schedulers.blocking</span> <span class="kn">import</span> <span class="n">BlockingScheduler</span>
<span class="kn">from</span> <span class="n">datetime</span> <span class="kn">import</span> <span class="n">datetime</span><span class="p">,</span> <span class="n">timedelta</span>
<span class="kn">from</span> <span class="n">apscheduler.jobstores.redis</span> <span class="kn">import</span> <span class="n">RedisJobStore</span>
<span class="kn">from</span> <span class="n">apscheduler.executors.pool</span> <span class="kn">import</span> <span class="n">ThreadPoolExecutor</span>


<span class="n">jobstores</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">default</span><span class="sh">'</span><span class="p">:</span> <span class="nc">RedisJobStore</span><span class="p">(</span><span class="n">jobs_key</span><span class="o">=</span><span class="sh">'</span><span class="s">test_job_key</span><span class="sh">'</span><span class="p">,</span> <span class="n">run_times_key</span><span class="o">=</span><span class="sh">'</span><span class="s">test_run_time_key</span><span class="sh">'</span><span class="p">,</span> <span class="n">host</span><span class="o">=</span><span class="sh">'</span><span class="s">localhost</span><span class="sh">'</span><span class="p">,</span> <span class="n">port</span><span class="o">=</span><span class="mi">6379</span><span class="p">,</span> <span class="n">password</span><span class="o">=</span><span class="sh">'</span><span class="s">1234</span><span class="sh">'</span><span class="p">)</span>
<span class="p">}</span>

<span class="n">executors</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">default</span><span class="sh">'</span><span class="p">:</span> <span class="nc">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
<span class="p">}</span>

<span class="n">job_defaults</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">coalesce</span><span class="sh">'</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">max_instances</span><span class="sh">'</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">misfire_grace_time</span><span class="sh">'</span><span class="p">:</span> <span class="mi">100000</span>
<span class="p">}</span>

<span class="n">scheduler</span> <span class="o">=</span> <span class="nc">BlockingScheduler</span><span class="p">(</span><span class="n">timezone</span><span class="o">=</span><span class="sh">'</span><span class="s">Asia/Seoul</span><span class="sh">'</span><span class="p">,</span><span class="n">jobstores</span><span class="o">=</span><span class="n">jobstores</span><span class="p">,</span> <span class="n">executors</span><span class="o">=</span><span class="n">executors</span><span class="p">,</span> <span class="n">job_defaults</span><span class="o">=</span><span class="n">job_defaults</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">alarm</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">in alarm</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">scheduler</span><span class="p">.</span><span class="nf">print_jobs</span><span class="p">(</span><span class="sh">'</span><span class="s">default</span><span class="sh">'</span><span class="p">)</span>
    <span class="c1">#print('Alarm! This alarm was scheduled at %s.' % time)
</span>    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">args : </span><span class="si">{</span><span class="n">args</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
    <span class="c1">#sys.exit()
</span>    <span class="c1">#raise Exception("ERROR!")
</span>
<span class="k">def</span> <span class="nf">my_listener</span><span class="p">(</span><span class="n">event</span><span class="p">):</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">event</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">in listener</span><span class="sh">'</span><span class="p">)</span>
    <span class="c1">#scheduler.print_jobs()
</span>    <span class="k">if</span> <span class="n">event</span><span class="p">.</span><span class="n">exception</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">The job crashed :(</span><span class="sh">'</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">The job worked :)</span><span class="sh">'</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">metric_batch</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">alarm_time</span> <span class="o">=</span> <span class="n">datetime</span><span class="p">.</span><span class="nf">now</span><span class="p">()</span> <span class="o">+</span> <span class="nf">timedelta</span><span class="p">(</span><span class="n">seconds</span><span class="o">=</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">scheduler</span><span class="p">.</span><span class="nf">add_job</span><span class="p">(</span><span class="n">alarm</span><span class="p">,</span> <span class="sh">'</span><span class="s">date</span><span class="sh">'</span><span class="p">,</span> <span class="n">run_date</span><span class="o">=</span><span class="n">alarm_time</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">[</span><span class="sa">f</span><span class="sh">'</span><span class="s">hello world </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="sh">'</span><span class="p">])</span>
    <span class="n">scheduler</span><span class="p">.</span><span class="nf">print_jobs</span><span class="p">(</span><span class="sh">'</span><span class="s">default</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">scheduler</span><span class="p">.</span><span class="nf">add_listener</span><span class="p">(</span><span class="n">my_listener</span><span class="p">,</span> <span class="n">EVENT_JOB_EXECUTED</span> <span class="o">|</span> <span class="n">EVENT_JOB_ERROR</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">To clear the alarms, run this example with the --clear argument.</span><span class="sh">'</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Press Ctrl+{0} to exit</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">'</span><span class="s">Break</span><span class="sh">'</span> <span class="k">if</span> <span class="n">os</span><span class="p">.</span><span class="n">name</span> <span class="o">==</span> <span class="sh">'</span><span class="s">nt</span><span class="sh">'</span> <span class="k">else</span> <span class="sh">'</span><span class="s">C</span><span class="sh">'</span><span class="p">))</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">scheduler</span><span class="p">.</span><span class="nf">start</span><span class="p">()</span>
    <span class="nf">except </span><span class="p">(</span><span class="nb">KeyboardInterrupt</span><span class="p">,</span> <span class="nb">SystemExit</span><span class="p">):</span>
        <span class="k">pass</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="sh">'</span><span class="s">__main__</span><span class="sh">'</span><span class="p">:</span>
    <span class="nf">metric_batch</span><span class="p">()</span>
</pre></table></code></div></div><p>하지만 job이 정상적으로 실행후 job정보가 redis에서 삭제가 되어야하는데, job이 실행하는 시작시점에 job정보가 사라지는 문제점이 있었다. 물론 job의 결과에 따라서 job을 다시 스케줄링하는 방법이 있었지만 실행도중 fail이 되는경우 해당 job을 다시 스케줄링할수 있는 방법은 없었다. 따라서 Producer Pod가 실행도중 종료되더라도, 실패한 job부터 실행할 수 있도록 Redis와 JobGenerator라는 앱을 추가한 버전이 v3 아키텍쳐이다.</p><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/22807942/150489033-93f45241-8501-4375-b3bc-ba51c2196028.png" alt="image" /></p><p>위 구조에서는 JobGenerator앱은 deployment 리소스를 사용해서 replica수를 3으로 설정하여 배포하였다. 따라서 3개의 Pod중 어느 2개의 Pod가 fail이 되더라도 job 정보를 계속 갱신할 수 있도록 하였다.</p><h3 id="4-적재대상이-되는-테이블의-칼럼-리스트-로드-자동화">4. 적재대상이 되는 테이블의 칼럼 리스트 로드 자동화</h3><p>원래 구조에서는 적재 대상이 되는 테이블의 칼럼 리스트를 python 리스트에 하드코딩 하는 형태로 구현되어있었다. 따라서 추가적으로 2022년 2월 기준으로 새로운 메트릭 수집 요청시 코드를 수정하고 도커 빌드를 새로해서 이미지 태그를 업데이트를 해야해서 번거롭다는 문제점이 있었다. 따라서 컨슈머 앱의 초기화 과정에서 적재해야할 테이블을 대상으로 칼럼 리스트를 로드할 수 있도록 자동화를 진행했다.</p><div lang="python" class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">get_table_list</span><span class="p">(</span><span class="n">database</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">schema</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="n">query</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">SHOW TABLES IN </span><span class="si">{</span><span class="n">database</span><span class="si">}</span><span class="s">.</span><span class="si">{</span><span class="n">schema</span><span class="si">}</span><span class="s">;</span><span class="sh">'</span>
    <span class="n">table_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="nf">get_snowflake_conn</span><span class="p">()</span> <span class="k">as</span> <span class="n">conn</span><span class="p">:</span>
        <span class="n">cur</span> <span class="o">=</span> <span class="n">conn</span><span class="p">.</span><span class="nf">cursor</span><span class="p">()</span>
        <span class="n">cur</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">cur</span><span class="p">:</span>
            <span class="n">table_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">lower</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">table_list</span>
</pre></table></code></div></div><p>이로서 새로운 메트릭 요청이 들어오면 헬름차트에 대상 쿼리가 되는 promQL과 대상 테이블 정보만 추가하고, Snowflake에 대상 테이블만 생성해주면 되어서 유지보수성이 향상되었다.</p><h2 id="개편구조의-장점">개편구조의 장점</h2><ol><li>안정적인 데이터 처리 : 메트릭별 JobGenerator가 replica 3으로 운용중이고, Producer,Consumer는 stateless하므로 중도에 fail이 되더라도 안전하게 데이터를 다시 처리 가능함. offset commit을 통해서, 카프카에서 데이터를 컨슘하여 snowflake에 적재하는 과정에서 at least once를 보장할 수 있다.<li>DevOps팀에게 backfill용 타노스를 요청할 경우가 거의 없어진다.<li>빠른 데이터 처리 : 대부분의 부하는 s3 upload 및 snowflake load에서 발생하는데 여러 컨슈머에서 병렬적으로 로그를 처리할 수 있으므로 속도가 빠르다</ol><h2 id="개편구조의-한계점과-해결책">개편구조의 한계점과 해결책</h2><p>결국 데이터 유실을 방지하기 위해서, Kafka를 도입하였고 Snowflake에 Unique 키를 지원하지 않음으로 인해 중복로그가 Snowflake에 적재될수 있게 되었다. 실시간으로 갱신되어야 하는 데이터가 아니라면 중복 row제거를 하는 batch를 돌릴수도 있겠지만, 실시간으로 갱신되어야하는 대시보드에서는 쿼리시점에 중복로그를 필터링 해야했다.</p><p>즉 다음 쿼리처럼 필터링을 해야했다.</p><div lang="sql" class="language-sql highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span>
<span class="p">(</span><span class="k">SELECT</span> <span class="o">*</span><span class="p">,</span> <span class="n">ROW_NUMBER</span><span class="p">()</span> <span class="n">OVER</span><span class="p">(</span><span class="k">PARTITION</span> <span class="k">BY</span> <span class="nb">TIMESTAMP</span><span class="p">,</span><span class="n">PROM_SHARD</span><span class="p">,</span><span class="k">CLUSTER</span> <span class="k">ORDER</span> <span class="k">BY</span> <span class="n">_COUNT</span><span class="p">)</span> <span class="k">AS</span> <span class="n">rn</span> 
<span class="k">FROM</span> <span class="n">DEV</span><span class="p">.</span><span class="n">SERVER</span><span class="p">.</span><span class="n">INGAME_AGGREGATED_CCU</span><span class="p">)</span>
<span class="k">WHERE</span> <span class="n">RN</span><span class="o">=</span><span class="mi">1</span><span class="p">;</span>
</pre></table></code></div></div><p>다만 저렇게 했을때, 테이블 풀스캔을 한다는 문제점이 있어서 쿼리시간이 지나치게 오래걸리는 문제점이 있었다. 이를 해결하기 위해서 FROM절에 필요한 하루치 데이터만 가져와서 중복로그를 제거하는 방식으로 수정되었다.</p><h2 id="참고">참고</h2><p>v3 아키텍쳐를 생각하는 시점에 아래와 같은 방법이 떠올랐다.</p><ol><li>snowflake에 적재되었는지 검사<li>적재 안되었으면 query, s3 upload, snowflake load<li>이중 실패했으면 1번 부터 다시 시작<li>만약 성공했으면 해당 job 삭제</ol><p>위 방법의 가장 큰 장점은 중복 적재가 안되는 것이고, 현재 중복로그 판별을 위한 칼럼을 추가할 필요없이 현재 테이블 구조대로 사용이 가능하다는 것이 장점이다.</p><p>하지만 로그가 많이 들어오는 경우, v3구조처럼 데이터를 병렬적으로 처리할 수 없다. 결국 데이터 중복을 제거하기 위해서 실시간성을 포기해야하는 것이다.</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/projectreview/'>ProjectReview</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=실시간 Prometheus To Snowflake 파이프라인 구축 - Study Log&url=https://jaegukim.github.io/posts/%EC%8B%A4%EC%8B%9C%EA%B0%84-prometheus-to-snowflake-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8-%EA%B5%AC%EC%B6%95/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=실시간 Prometheus To Snowflake 파이프라인 구축 - Study Log&u=https://jaegukim.github.io/posts/%EC%8B%A4%EC%8B%9C%EA%B0%84-prometheus-to-snowflake-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8-%EA%B5%AC%EC%B6%95/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=실시간 Prometheus To Snowflake 파이프라인 구축 - Study Log&url=https://jaegukim.github.io/posts/%EC%8B%A4%EC%8B%9C%EA%B0%84-prometheus-to-snowflake-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8-%EA%B5%AC%EC%B6%95/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink('', 'Link copied successfully!')" data-toggle="tooltip" data-placement="top" title="Copy link"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/software-engineering-at-google/">Software Engineering at Google</a><li><a href="/posts/til/">TIL</a><li><a href="/posts/custom-default-backend-%EC%84%A4%EC%A0%95%ED%95%98%EA%B8%B0/">custom error page 띄우기</a><li><a href="/posts/cors-setting/">CORS setting</a><li><a href="/posts/helm-chart/">Helm Chart</a></ul></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/software-engineering-at-google/"><div class="card-body"> <span class="timeago small" >Oct 2<i class="unloaded">2023-10-02T19:12:00+08:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Software Engineering at Google</h3><div class="text-muted small"><p> 챕터1 Time and Change Software를 장기적으로 유지보수가능하게 하는 작업은 지속적인 전투(constant battle)이다. Hyrum’s Law API의 충분한 사용자가 있는 경우, 주어진 계약에서 무엇을 약속하는지는 중요하지 않다. : 모든 관찰가능한 당신의 시스템의 행위가 다른 누군가에 의해 의존될 것이다. ...</p></div></div></a></div><div class="card"> <a href="/posts/finance-til/"><div class="card-body"> <span class="timeago small" >Mar 5<i class="unloaded">2023-03-05T13:07:00+08:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Finance TIL</h3><div class="text-muted small"><p> 2023-03-05 leverage : 부채를 갖고 하는 투자 stable coin : 가격 변동서어을 최소화하도록 설계된 암호화폐, 1달러를 예금할 경우 1코인을 발행해줌으로써 암호화폐의 1대 1가치를 유지하며, 이를 pegging 이라고 말한다.</p></div></div></a></div><div class="card"> <a href="/posts/effective-go/"><div class="card-body"> <span class="timeago small" >Feb 27<i class="unloaded">2023-02-27T10:37:00+08:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Effective Go</h3><div class="text-muted small"><p> Package name은 lower case, single-word names; there should be no need for underscores or mixedCaps Getters : Get을 prefix로 붙이지 않는다. Setter의 경우는 Set을 prefix로 붙일수 있다. Interface Names ...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/snowflake-queries/" class="btn btn-outline-primary" prompt="Older"><p>[Snowflake] Queries</p></a> <a href="/posts/hbase/" class="btn btn-outline-primary" prompt="Newer"><p>HBase 개요</p></a></div><div id="disqus" class="pt-2 pb-2"><p class="text-center text-muted small pb-5"> Comments powered by <a href="https://disqus.com/">Disqus</a>.</p></div><script src="/assets/js/lib/jquery.disqusloader.min.js"></script> <script> const options = { scriptUrl: '//jaegukim.disqus.com/embed.js', disqusConfig: function() { this.page.title = '실시간 Prometheus To Snowflake 파이프라인 구축'; this.page.url = 'https://jaegukim.github.io/posts/%EC%8B%A4%EC%8B%9C%EA%B0%84-prometheus-to-snowflake-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8-%EA%B5%AC%EC%B6%95/'; this.page.identifier = '/posts/%EC%8B%A4%EC%8B%9C%EA%B0%84-prometheus-to-snowflake-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8-%EA%B5%AC%EC%B6%95/'; } }; $.disqusLoader('#disqus', options); </script></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://twitter.com/username">Jaegoo.Kim</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://jaegukim.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script>
